{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === EDIT THESE PATHS ===\n",
    "pkl_path = \"slake_df_captions\"    # pickle file with extra columns\n",
    "csv2_path = \"Results/qwen7b_oneword_filtered.csv\"  # base CSV that will be overwritten\n",
    "# ========================\n",
    "\n",
    "# Load first file (pickle, assumed to be a pandas DataFrame)\n",
    "df1 = pd.read_pickle(pkl_path)\n",
    "\n",
    "# Load second file (CSV)\n",
    "df2 = pd.read_csv(csv2_path)\n",
    "\n",
    "# Find columns in df1 that are NOT already in df2\n",
    "unique_cols_df1 = [col for col in df1.columns if col not in df2.columns]\n",
    "\n",
    "# Take only those unique columns from df1\n",
    "df1_unique = df1[unique_cols_df1]\n",
    "\n",
    "# Combine: keep all columns from df2, add unique ones from df1\n",
    "# Rows are aligned by index; if lengths differ, you'll get NaNs where missing\n",
    "combined = pd.concat([df2, df1_unique], axis=1)\n",
    "\n",
    "# Overwrite the second CSV with the combined result\n",
    "combined.to_csv(csv2_path, index=False)\n",
    "print(f\"Combined file saved to: {csv2_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb60cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Install dependencies (run this cell once in Colab)\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from bert_score import score as bertscore_score\n",
    "\n",
    "# ============================================================\n",
    "# Load your CSV\n",
    "# ============================================================\n",
    "csv_path = \"Results/qwen7b_oneword_filtered.csv\"  # <-- EDIT THIS\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "assert \"qwen_answer\" in df.columns, \"Column 'qwen_answer' not found in CSV\"\n",
    "assert \"gt_answer\" in df.columns, \"Column 'gt_answer' not found in CSV\"\n",
    "\n",
    "short_answers = df[\"qwen_answer\"].astype(str).tolist()\n",
    "gt_answers    = df[\"gt_answer\"].astype(str).tolist()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ============================================================\n",
    "# 1. BERTScore (F1 only) using RoBERTa\n",
    "# ============================================================\n",
    "print(\"Computing BERTScore F1...\")\n",
    "\n",
    "P, R, F1 = bertscore_score(\n",
    "    short_answers,\n",
    "    gt_answers,\n",
    "    lang=\"en\",\n",
    "    model_type=\"roberta-large\"\n",
    ")\n",
    "\n",
    "df[\"bertscore_f1\"] = F1.cpu().numpy()\n",
    "\n",
    "# ============================================================\n",
    "# 2. Sentence-BERT similarity (single score, called sbert_f1)\n",
    "# ============================================================\n",
    "print(\"Computing Sentence-BERT similarity...\")\n",
    "\n",
    "sbert_model_name = \"all-MiniLM-L6-v2\"\n",
    "sbert_model = SentenceTransformer(sbert_model_name, device=str(device))\n",
    "\n",
    "emb_short = sbert_model.encode(\n",
    "    short_answers,\n",
    "    convert_to_tensor=True,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "emb_gt = sbert_model.encode(\n",
    "    gt_answers,\n",
    "    convert_to_tensor=True,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "cosine_matrix = util.cos_sim(emb_short, emb_gt)\n",
    "cosine_diag = cosine_matrix.diag().cpu().numpy()\n",
    "\n",
    "# Treat cosine similarity as the SBERT \"F1-like\" score\n",
    "df[\"sbert_f1\"] = cosine_diag\n",
    "\n",
    "# ============================================================\n",
    "# 3. NLI with RoBERTa (entailment & contradiction means only)\n",
    "# ============================================================\n",
    "print(\"Loading RoBERTa NLI model...\")\n",
    "\n",
    "nli_model_name = \"roberta-large-mnli\"\n",
    "nli_tokenizer = AutoTokenizer.from_pretrained(nli_model_name)\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model_name).to(device)\n",
    "\n",
    "# label indices: 0 = contradiction, 1 = neutral, 2 = entailment\n",
    "def nli_directional_scores(premises, hypotheses, batch_size=16, max_length=256):\n",
    "    entail_list = []\n",
    "    contra_list = []\n",
    "\n",
    "    nli_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(premises), batch_size):\n",
    "            batch_p = premises[i:i+batch_size]\n",
    "            batch_h = hypotheses[i:i+batch_size]\n",
    "\n",
    "            enc = nli_tokenizer(\n",
    "                batch_p,\n",
    "                batch_h,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            logits = nli_model(**enc).logits\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "            contra = probs[:, 0]   # contradiction\n",
    "            entail = probs[:, 2]   # entailment\n",
    "\n",
    "            contra_list.extend(contra.cpu().numpy())\n",
    "            entail_list.extend(entail.cpu().numpy())\n",
    "\n",
    "    return np.array(entail_list), np.array(contra_list)\n",
    "\n",
    "print(\"Computing NLI scores (short -> gt)...\")\n",
    "ent_s2g, contra_s2g = nli_directional_scores(short_answers, gt_answers)\n",
    "\n",
    "print(\"Computing NLI scores (gt -> short)...\")\n",
    "ent_g2s, contra_g2s = nli_directional_scores(gt_answers, short_answers)\n",
    "\n",
    "# Only keep the means\n",
    "df[\"nli_entail_mean\"] = (ent_s2g + ent_g2s) / 2.0\n",
    "df[\"nli_contra_mean\"] = (contra_s2g + contra_g2s) / 2.0\n",
    "\n",
    "# ============================================================\n",
    "# Save back to the original CSV (append columns)\n",
    "# ============================================================\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"\\nDone! Appended these columns to your CSV:\")\n",
    "print(\"  - bertscore_f1\")\n",
    "print(\"  - sbert_f1\")\n",
    "print(\"  - nli_entail_mean\")\n",
    "print(\"  - nli_contra_mean\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ed998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Analyze multiple CSV files with score columns.\n",
    "\n",
    "- Computes overall mean of each score per file.\n",
    "- Computes cluster-averages by:\n",
    "    - modality\n",
    "    - location\n",
    "    - content_type\n",
    "- Produces plots (matplotlib) to compare scores across files and clusters.\n",
    "\n",
    "Usage:\n",
    "    Just run: python analyze_scores.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# YOUR CSV PATHS\n",
    "# ---------------------------------------------------------------------\n",
    "CSV_PATHS: List[str] = [\n",
    "    \"Results/qwen7b_oneword_inaccurate.csv\",\n",
    "    \"Results/qwen7b_oneword_irrelevant.csv\",\n",
    "    \"Results/qwen7b_oneword_missing.csv\",\n",
    "    \"Results/qwen7b_oneword_noisy.csv\",\n",
    "    \"Results/qwen7b_oneword_original.csv\",\n",
    "    \"Results/qwen7b_oneword_severely_inaccurate.csv\",\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Desired order on the x-axis (severely inaccurate FIRST)\n",
    "# ---------------------------------------------------------------------\n",
    "FILE_ORDER: List[str] = [\n",
    "    \"qwen7b_oneword_severely_inaccurate.csv\",\n",
    "    \"qwen7b_oneword_inaccurate.csv\",\n",
    "    \"qwen7b_oneword_irrelevant.csv\",\n",
    "    \"qwen7b_oneword_missing.csv\",\n",
    "    \"qwen7b_oneword_noisy.csv\",\n",
    "    \"qwen7b_oneword_original.csv\",\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# SCORE COLUMNS: your 4 scores\n",
    "# ---------------------------------------------------------------------\n",
    "SCORE_COLUMNS: List[str] = [\n",
    "    \"bertscore_f1\",\n",
    "    \"sbert_f1\",\n",
    "    \"nli_entail_mean\",\n",
    "    \"nli_contra_mean\",\n",
    "]\n",
    "\n",
    "# Grouping columns\n",
    "GROUP_COLUMNS = [\"modality\", \"location\", \"content_type\"]\n",
    "\n",
    "\n",
    "def load_and_tag_csv(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load a CSV and add a 'source_file' column with just the basename.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"source_file\"] = os.path.basename(path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def ensure_output_dir() -> str:\n",
    "    out_dir = \"score_analysis_outputs\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "def file_label(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Turn 'qwen7b_severely_inaccurate.csv' into 'severely_inaccurate'.\n",
    "    Generic:\n",
    "      - strip .csv if present\n",
    "      - strip 'qwen7b_' prefix if present\n",
    "    \"\"\"\n",
    "    base = name\n",
    "    if base.endswith(\".csv\"):\n",
    "        base = base[:-4]\n",
    "    prefix = \"qwen7b_oneword_\"\n",
    "    if base.startswith(prefix):\n",
    "        base = base[len(prefix):]\n",
    "    return base\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# PLOTTING HELPERS (matplotlib)\n",
    "# ==============================\n",
    "\n",
    "def plot_overall_means_by_file(overall_by_file: pd.DataFrame,\n",
    "                               score_cols: List[str],\n",
    "                               out_dir: str,\n",
    "                               file_order: List[str]):\n",
    "    \"\"\"\n",
    "    For each metric, make a bar chart of mean score per file\n",
    "    using the specified file_order and short labels on x-axis.\n",
    "    \"\"\"\n",
    "    # Reorder rows to match file_order\n",
    "    overall_by_file = overall_by_file.set_index(\"source_file\").reindex(file_order).dropna(how=\"all\")\n",
    "    overall_by_file = overall_by_file.reset_index()\n",
    "\n",
    "    labels = [file_label(f) for f in overall_by_file[\"source_file\"]]\n",
    "\n",
    "    for metric in score_cols:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.bar(labels, overall_by_file[metric])\n",
    "        ax.set_title(f\"Mean {metric} by file\")\n",
    "        ax.set_ylabel(\"Mean score\")\n",
    "        ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "        fig.tight_layout()\n",
    "        out_path = os.path.join(out_dir, f\"overall_mean_{metric}_by_file.png\")\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(\"Saved plot:\", out_path)\n",
    "\n",
    "\n",
    "def plot_score_distributions_by_file(all_df: pd.DataFrame,\n",
    "                                     score_cols: List[str],\n",
    "                                     out_dir: str,\n",
    "                                     file_order: List[str]):\n",
    "    \"\"\"\n",
    "    For each metric, make a boxplot of the distribution per file,\n",
    "    with x-axis ordered by file_order and short labels.\n",
    "    \"\"\"\n",
    "    # Only keep files that are actually present\n",
    "    files_present = [f for f in file_order if f in all_df[\"source_file\"].unique()]\n",
    "    labels_present = [file_label(f) for f in files_present]\n",
    "\n",
    "    for metric in score_cols:\n",
    "        data = [\n",
    "            all_df.loc[all_df[\"source_file\"] == f, metric].dropna().values\n",
    "            for f in files_present\n",
    "        ]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.boxplot(data)\n",
    "        ax.set_title(f\"Distribution of {metric} by file\")\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.set_xticks(np.arange(1, len(labels_present) + 1))\n",
    "        ax.set_xticklabels(labels_present, rotation=45, ha=\"right\")\n",
    "        fig.tight_layout()\n",
    "        out_path = os.path.join(out_dir, f\"boxplot_{metric}_by_file.png\")\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(\"Saved plot:\", out_path)\n",
    "\n",
    "\n",
    "def plot_group_overall_bars(col: str,\n",
    "                            by_group_overall: pd.DataFrame,\n",
    "                            score_cols: List[str],\n",
    "                            out_dir: str):\n",
    "    \"\"\"\n",
    "    For each metric, bar chart of overall mean score per group value.\n",
    "    \"\"\"\n",
    "    groups = by_group_overall[col].astype(str).tolist()\n",
    "    x = np.arange(len(groups))\n",
    "\n",
    "    for metric in score_cols:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        y = by_group_overall[metric].values\n",
    "        ax.bar(x, y)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(groups, rotation=45, ha=\"right\")\n",
    "        ax.set_ylabel(\"Mean score\")\n",
    "        ax.set_title(f\"Overall mean {metric} by {col}\")\n",
    "        fig.tight_layout()\n",
    "        out_path = os.path.join(out_dir, f\"overall_mean_{metric}_by_{col}.png\")\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(\"Saved plot:\", out_path)\n",
    "\n",
    "\n",
    "def plot_group_heatmaps(col: str,\n",
    "                        by_file_and_group: pd.DataFrame,\n",
    "                        score_cols: List[str],\n",
    "                        out_dir: str,\n",
    "                        file_order: List[str]):\n",
    "    \"\"\"\n",
    "    For each metric, heatmap of mean score with:\n",
    "        y-axis: group values (e.g. modality/location/content_type)\n",
    "        x-axis: source_file ordered by file_order, using short labels.\n",
    "    \"\"\"\n",
    "    for metric in score_cols:\n",
    "        # pivot: rows = group, columns = file, values = metric mean\n",
    "        pivot = by_file_and_group.pivot(index=col, columns=\"source_file\", values=metric)\n",
    "\n",
    "        # Reorder columns (files) according to file_order\n",
    "        cols_present = [f for f in file_order if f in pivot.columns]\n",
    "        pivot = pivot[cols_present]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        im = ax.imshow(pivot.values, aspect=\"auto\", origin=\"upper\")\n",
    "\n",
    "        # ticks and labels\n",
    "        ax.set_xticks(np.arange(len(pivot.columns)))\n",
    "        short_labels = [file_label(c) for c in pivot.columns]\n",
    "        ax.set_xticklabels(short_labels, rotation=45, ha=\"right\")\n",
    "        ax.set_yticks(np.arange(len(pivot.index)))\n",
    "        ax.set_yticklabels(pivot.index.astype(str))\n",
    "\n",
    "        ax.set_xlabel(\"file\")\n",
    "        ax.set_ylabel(col)\n",
    "        ax.set_title(f\"{metric} by {col} and file\")\n",
    "\n",
    "        # colorbar\n",
    "        cbar = fig.colorbar(im, ax=ax)\n",
    "        cbar.set_label(\"Mean score\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        out_path = os.path.join(out_dir, f\"heatmap_{metric}_by_{col}_and_file.png\")\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(\"Saved plot:\", out_path)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# MAIN ANALYSIS\n",
    "# ==============================\n",
    "\n",
    "def main():\n",
    "    if not CSV_PATHS:\n",
    "        print(\"ERROR: Please provide at least one CSV path in CSV_PATHS.\")\n",
    "        return\n",
    "\n",
    "    # Load and concatenate all CSVs\n",
    "    dfs = []\n",
    "    for path in CSV_PATHS:\n",
    "        if not os.path.isfile(path):\n",
    "            print(f\"WARNING: File not found, skipping: {path}\")\n",
    "            continue\n",
    "        df = load_and_tag_csv(path)\n",
    "        dfs.append(df)\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"ERROR: No valid CSV files loaded. Check CSV_PATHS.\")\n",
    "        return\n",
    "\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Ensure score columns exist\n",
    "    missing_scores = [c for c in SCORE_COLUMNS if c not in all_df.columns]\n",
    "    if missing_scores:\n",
    "        print(f\"ERROR: These SCORE_COLUMNS are missing in the data: {missing_scores}\")\n",
    "        return\n",
    "\n",
    "    score_cols = SCORE_COLUMNS\n",
    "\n",
    "    # Make source_file a categorical with desired order\n",
    "    all_df[\"source_file\"] = pd.Categorical(\n",
    "        all_df[\"source_file\"],\n",
    "        categories=FILE_ORDER,\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # 1. Overall average of scores per CSV file\n",
    "    # -----------------------------------------------------------------\n",
    "    overall_by_file = (\n",
    "        all_df.groupby(\"source_file\", observed=True)[score_cols]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # 2. Cluster-averages by modality, location, content_type\n",
    "    # -----------------------------------------------------------------\n",
    "    summaries = {}\n",
    "\n",
    "    for col in GROUP_COLUMNS:\n",
    "        if col not in all_df.columns:\n",
    "            print(f\"WARNING: Column '{col}' not found in data. Skipping grouping by this column.\")\n",
    "            continue\n",
    "\n",
    "        # Per file + group (e.g., file & modality)\n",
    "        by_file_and_group = (\n",
    "            all_df.groupby([\"source_file\", col], observed=True)[score_cols]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Across all files combined, grouped only by that column\n",
    "        by_group_overall = (\n",
    "            all_df.groupby(col, observed=True)[score_cols]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        summaries[col] = {\n",
    "            \"by_file_and_group\": by_file_and_group,\n",
    "            \"by_group_overall\": by_group_overall,\n",
    "        }\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Save numeric outputs\n",
    "    # -----------------------------------------------------------------\n",
    "    out_dir = ensure_output_dir()\n",
    "\n",
    "    overall_path = os.path.join(out_dir, \"overall_means_by_file.csv\")\n",
    "    overall_by_file.to_csv(overall_path, index=False)\n",
    "    print(\"\\nSaved overall means per file to:\", overall_path)\n",
    "\n",
    "    for col, data in summaries.items():\n",
    "        by_file_path = os.path.join(out_dir, f\"means_by_file_and_{col}.csv\")\n",
    "        by_group_path = os.path.join(out_dir, f\"means_by_{col}_overall.csv\")\n",
    "\n",
    "        data[\"by_file_and_group\"].to_csv(by_file_path, index=False)\n",
    "        data[\"by_group_overall\"].to_csv(by_group_path, index=False)\n",
    "\n",
    "        print(f\"Saved means by file and {col} to:\", by_file_path)\n",
    "        print(f\"Saved overall means by {col} to:\", by_group_path)\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Plotting (matplotlib only)\n",
    "    # -----------------------------------------------------------------\n",
    "    # 1) Overall comparison of files\n",
    "    plot_overall_means_by_file(overall_by_file, score_cols, out_dir, FILE_ORDER)\n",
    "    plot_score_distributions_by_file(all_df, score_cols, out_dir, FILE_ORDER)\n",
    "\n",
    "    # 2) Group-based plots\n",
    "    for col, data in summaries.items():\n",
    "        print(f\"\\nCreating plots for grouping by '{col}'...\")\n",
    "        plot_group_overall_bars(\n",
    "            col=col,\n",
    "            by_group_overall=data[\"by_group_overall\"],\n",
    "            score_cols=score_cols,\n",
    "            out_dir=out_dir,\n",
    "        )\n",
    "        plot_group_heatmaps(\n",
    "            col=col,\n",
    "            by_file_and_group=data[\"by_file_and_group\"],\n",
    "            score_cols=score_cols,\n",
    "            out_dir=out_dir,\n",
    "            file_order=FILE_ORDER,\n",
    "        )\n",
    "\n",
    "    # Quick sanity check in stdout\n",
    "    print(\"\\n=== Overall means per file (head) ===\")\n",
    "    print(overall_by_file.head())\n",
    "\n",
    "    for col, data in summaries.items():\n",
    "        print(f\"\\n=== Means by file and {col} (head) ===\")\n",
    "        print(data[\"by_file_and_group\"].head())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Analyze multiple CSV files with score columns.\n",
    "\n",
    "- Computes overall mean of each score per file.\n",
    "- Computes cluster-averages by:\n",
    "    - modality\n",
    "    - location\n",
    "    - content_type\n",
    "- Produces plots (matplotlib) to compare scores across files and clusters.\n",
    "\n",
    "Usage:\n",
    "    Just run: python analyze_scores.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# PLOT STYLE (bigger fonts + less gaudy defaults)\n",
    "# ---------------------------------------------------------------------\n",
    "FONT_SCALE = 2.0  # \"double the font size\"\n",
    "\n",
    "\n",
    "def set_plot_style(font_scale: float = 2.0) -> None:\n",
    "    base = float(plt.rcParams.get(\"font.size\", 10.0))\n",
    "    fs = base * font_scale\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        \"font.size\": fs,\n",
    "        \"axes.titlesize\": fs * 1.2,\n",
    "        \"axes.labelsize\": fs,\n",
    "        \"xtick.labelsize\": fs * 0.9,\n",
    "        \"ytick.labelsize\": fs * 0.9,\n",
    "        \"legend.fontsize\": fs * 0.9,\n",
    "        \"figure.titlesize\": fs * 1.2,\n",
    "\n",
    "        # Heatmap defaults (muted + readable)\n",
    "        \"image.cmap\": \"cividis\",\n",
    "        \"image.interpolation\": \"nearest\",\n",
    "    })\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# YOUR CSV PATHS\n",
    "# ---------------------------------------------------------------------\n",
    "CSV_PATHS: List[str] = [\n",
    "    \"Results/qwen7b_oneword_inaccurate.csv\",\n",
    "    \"Results/qwen7b_oneword_irrelevant.csv\",\n",
    "    \"Results/qwen7b_oneword_missing.csv\",\n",
    "    \"Results/qwen7b_oneword_noisy.csv\",\n",
    "    \"Results/qwen7b_oneword_original.csv\",\n",
    "    \"Results/qwen7b_oneword_severely_inaccurate.csv\",\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Desired order on the x-axis (severely inaccurate FIRST)\n",
    "# ---------------------------------------------------------------------\n",
    "FILE_ORDER: List[str] = [\n",
    "    \"qwen7b_oneword_severely_inaccurate.csv\",\n",
    "    \"qwen7b_oneword_inaccurate.csv\",\n",
    "    \"qwen7b_oneword_irrelevant.csv\",\n",
    "    \"qwen7b_oneword_missing.csv\",\n",
    "    \"qwen7b_oneword_noisy.csv\",\n",
    "    \"qwen7b_oneword_original.csv\",\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# SCORE COLUMNS: your 4 scores\n",
    "# ---------------------------------------------------------------------\n",
    "SCORE_COLUMNS: List[str] = [\n",
    "    \"bertscore_f1\",\n",
    "    \"sbert_f1\",\n",
    "    \"nli_entail_mean\",\n",
    "    \"nli_contra_mean\",\n",
    "]\n",
    "\n",
    "# Grouping columns\n",
    "GROUP_COLUMNS = [\"modality\", \"location\", \"content_type\"]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Pretty metric names for plots\n",
    "# ---------------------------------------------------------------------\n",
    "METRIC_LABELS: Dict[str, str] = {\n",
    "    \"nli_entail_mean\": \"NLI Entailment\",\n",
    "    \"nli_contra_mean\": \"NLI contradiction\",\n",
    "}\n",
    "\n",
    "\n",
    "def metric_label(metric: str) -> str:\n",
    "    \"\"\"Map raw metric column names to nicer plot labels.\"\"\"\n",
    "    return METRIC_LABELS.get(metric, metric)\n",
    "\n",
    "\n",
    "def load_and_tag_csv(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load a CSV and add a 'source_file' column with just the basename.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"source_file\"] = os.path.basename(path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def ensure_output_dir() -> str:\n",
    "    out_dir = \"score_analysis_outputs\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "def file_label(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Turn 'qwen7b_oneword_severely_inaccurate.csv' into 'severely_inaccurate',\n",
    "    with a special case to make 'severely_inaccurate' double-lined on axes.\n",
    "    \"\"\"\n",
    "    base = name\n",
    "    if base.endswith(\".csv\"):\n",
    "        base = base[:-4]\n",
    "    prefix = \"qwen7b_oneword_\"\n",
    "    if base.startswith(prefix):\n",
    "        base = base[len(prefix):]\n",
    "\n",
    "    # double-line the x-axis label when it appears\n",
    "    if base == \"severely_inaccurate\":\n",
    "        return \"severely\\ninaccurate\"\n",
    "\n",
    "    return base\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# PLOTTING HELPERS (matplotlib)\n",
    "# ==============================\n",
    "\n",
    "def plot_overall_means_by_file(overall_by_file: pd.DataFrame,\n",
    "                               score_cols: List[str],\n",
    "                               out_dir: str,\n",
    "                               file_order: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    For each metric, make a bar chart of mean score per dataset\n",
    "    using the specified file_order and short labels on x-axis.\n",
    "    \"\"\"\n",
    "    overall_by_file = overall_by_file.set_index(\"source_file\").reindex(file_order).dropna(how=\"all\")\n",
    "    overall_by_file = overall_by_file.reset_index()\n",
    "\n",
    "    labels = [file_label(f) for f in overall_by_file[\"source_file\"]]\n",
    "\n",
    "    for metric in score_cols:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.bar(np.arange(len(labels)), overall_by_file[metric], color=\"0.35\", alpha=0.9)\n",
    "        ax.set_title(f\"Mean {metric_label(metric)} across data\")\n",
    "        ax.set_ylabel(\"Mean score\")\n",
    "        ax.set_xticks(np.arange(len(labels)))\n",
    "        ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "        fig.tight_layout()\n",
    "        out_path = os.path.join(out_dir, f\"overall_mean_{metric}_by_file.png\")\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(\"Saved plot:\", out_path)\n",
    "\n",
    "\n",
    "def plot_score_distributions_by_file(all_df: pd.DataFrame,\n",
    "                                     score_cols: List[str],\n",
    "                                     out_dir: str,\n",
    "                                     file_order: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    For each metric, make a boxplot of the distribution per dataset,\n",
    "    with x-axis ordered by file_order and short labels.\n",
    "    \"\"\"\n",
    "    files_present = [f for f in file_order if f in all_df[\"source_file\"].unique()]\n",
    "    labels_present = [file_label(f) for f in files_present]\n",
    "\n",
    "    for metric in score_cols:\n",
    "        data = [\n",
    "            all_df.loc[all_df[\"source_file\"] == f, metric].dropna().values\n",
    "            for f in files_present\n",
    "        ]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.boxplot(data)\n",
    "        ax.set_title(f\"Distribution of {metric_label(metric)} across data\")\n",
    "        ax.set_ylabel(metric_label(metric))\n",
    "        ax.set_xticks(np.arange(1, len(labels_present) + 1))\n",
    "        ax.set_xticklabels(labels_present, rotation=45, ha=\"right\")\n",
    "        fig.tight_layout()\n",
    "        out_path = os.path.join(out_dir, f\"boxplot_{metric}_by_file.png\")\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(\"Saved plot:\", out_path)\n",
    "\n",
    "\n",
    "def plot_group_overall_bars(col: str,\n",
    "                            by_group_overall: pd.DataFrame,\n",
    "                            score_cols: List[str],\n",
    "                            out_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    For each metric, bar chart of overall mean score per group value.\n",
    "    \"\"\"\n",
    "    groups = by_group_overall[col].astype(str).tolist()\n",
    "    x = np.arange(len(groups))\n",
    "\n",
    "    for metric in score_cols:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        y = by_group_overall[metric].values\n",
    "        ax.bar(x, y, color=\"0.35\", alpha=0.9)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(groups, rotation=45, ha=\"right\")\n",
    "        ax.set_ylabel(\"Mean score\")\n",
    "        ax.set_title(f\"Overall mean {metric_label(metric)} by {col}\")\n",
    "        fig.tight_layout()\n",
    "        out_path = os.path.join(out_dir, f\"overall_mean_{metric}_by_{col}.png\")\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(\"Saved plot:\", out_path)\n",
    "\n",
    "\n",
    "def plot_group_heatmaps(col: str,\n",
    "                        by_file_and_group: pd.DataFrame,\n",
    "                        score_cols: List[str],\n",
    "                        out_dir: str,\n",
    "                        file_order: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    For each metric, heatmap of mean score with:\n",
    "        y-axis: group values (e.g. modality/location/content_type)\n",
    "        x-axis: dataset (source_file) ordered by file_order, using short labels.\n",
    "    Adds numeric annotations and uses a muted colormap.\n",
    "    \"\"\"\n",
    "    for metric in score_cols:\n",
    "        pivot = by_file_and_group.pivot(index=col, columns=\"source_file\", values=metric)\n",
    "\n",
    "        cols_present = [f for f in file_order if f in pivot.columns]\n",
    "        pivot = pivot[cols_present]\n",
    "\n",
    "        vals = pivot.values.astype(float)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        im = ax.imshow(vals, aspect=\"auto\", origin=\"upper\", cmap=\"cividis\")\n",
    "\n",
    "        ax.set_xticks(np.arange(len(pivot.columns)))\n",
    "        short_labels = [file_label(c) for c in pivot.columns]\n",
    "        ax.set_xticklabels(short_labels, rotation=45, ha=\"right\")\n",
    "\n",
    "        ax.set_yticks(np.arange(len(pivot.index)))\n",
    "        ax.set_yticklabels(pivot.index.astype(str))\n",
    "\n",
    "        ax.set_xlabel(\"captions\")\n",
    "        ax.set_ylabel(col)\n",
    "        ax.set_title(f\"{metric_label(metric)} by {col} across data\")\n",
    "\n",
    "        # annotate each cell\n",
    "        norm = im.norm\n",
    "        cmap = im.get_cmap()\n",
    "        for i in range(vals.shape[0]):\n",
    "            for j in range(vals.shape[1]):\n",
    "                v = vals[i, j]\n",
    "                if np.isnan(v):\n",
    "                    continue\n",
    "                rgba = cmap(norm(v))\n",
    "                luminance = 0.299 * rgba[0] + 0.587 * rgba[1] + 0.114 * rgba[2]\n",
    "                txt_color = \"black\" if luminance > 0.6 else \"white\"\n",
    "                ax.text(j, i, f\"{v:.3f}\", ha=\"center\", va=\"center\", color=txt_color)\n",
    "\n",
    "        cbar = fig.colorbar(im, ax=ax)\n",
    "        cbar.set_label(\"Mean score\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        out_path = os.path.join(out_dir, f\"heatmap_{metric}_by_{col}_and_file.png\")\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(\"Saved plot:\", out_path)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# MAIN ANALYSIS\n",
    "# ==============================\n",
    "\n",
    "def main() -> None:\n",
    "    if not CSV_PATHS:\n",
    "        print(\"ERROR: Please provide at least one CSV path in CSV_PATHS.\")\n",
    "        return\n",
    "\n",
    "    # Load and concatenate all CSVs\n",
    "    dfs = []\n",
    "    for path in CSV_PATHS:\n",
    "        if not os.path.isfile(path):\n",
    "            print(f\"WARNING: File not found, skipping: {path}\")\n",
    "            continue\n",
    "        df = load_and_tag_csv(path)\n",
    "        dfs.append(df)\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"ERROR: No valid CSV files loaded. Check CSV_PATHS.\")\n",
    "        return\n",
    "\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Ensure score columns exist\n",
    "    missing_scores = [c for c in SCORE_COLUMNS if c not in all_df.columns]\n",
    "    if missing_scores:\n",
    "        print(f\"ERROR: These SCORE_COLUMNS are missing in the data: {missing_scores}\")\n",
    "        return\n",
    "\n",
    "    score_cols = SCORE_COLUMNS\n",
    "\n",
    "    # Make source_file a categorical with desired order\n",
    "    all_df[\"source_file\"] = pd.Categorical(\n",
    "        all_df[\"source_file\"],\n",
    "        categories=FILE_ORDER,\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # 1. Overall average of scores per CSV file\n",
    "    # -----------------------------------------------------------------\n",
    "    overall_by_file = (\n",
    "        all_df.groupby(\"source_file\", observed=True)[score_cols]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # 2. Cluster-averages by modality, location, content_type\n",
    "    # -----------------------------------------------------------------\n",
    "    summaries = {}\n",
    "\n",
    "    for col in GROUP_COLUMNS:\n",
    "        if col not in all_df.columns:\n",
    "            print(f\"WARNING: Column '{col}' not found in data. Skipping grouping by this column.\")\n",
    "            continue\n",
    "\n",
    "        by_file_and_group = (\n",
    "            all_df.groupby([\"source_file\", col], observed=True)[score_cols]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        by_group_overall = (\n",
    "            all_df.groupby(col, observed=True)[score_cols]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        summaries[col] = {\n",
    "            \"by_file_and_group\": by_file_and_group,\n",
    "            \"by_group_overall\": by_group_overall,\n",
    "        }\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Save numeric outputs\n",
    "    # -----------------------------------------------------------------\n",
    "    out_dir = ensure_output_dir()\n",
    "\n",
    "    overall_path = os.path.join(out_dir, \"overall_means_by_file.csv\")\n",
    "    overall_by_file.to_csv(overall_path, index=False)\n",
    "    print(\"\\nSaved overall means per file to:\", overall_path)\n",
    "\n",
    "    for col, data in summaries.items():\n",
    "        by_file_path = os.path.join(out_dir, f\"means_by_file_and_{col}.csv\")\n",
    "        by_group_path = os.path.join(out_dir, f\"means_by_{col}_overall.csv\")\n",
    "\n",
    "        data[\"by_file_and_group\"].to_csv(by_file_path, index=False)\n",
    "        data[\"by_group_overall\"].to_csv(by_group_path, index=False)\n",
    "\n",
    "        print(f\"Saved means by file and {col} to:\", by_file_path)\n",
    "        print(f\"Saved overall means by {col} to:\", by_group_path)\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Plotting (matplotlib only)\n",
    "    # -----------------------------------------------------------------\n",
    "    set_plot_style(FONT_SCALE)\n",
    "\n",
    "    # 1) Overall comparison of datasets\n",
    "    plot_overall_means_by_file(overall_by_file, score_cols, out_dir, FILE_ORDER)\n",
    "    plot_score_distributions_by_file(all_df, score_cols, out_dir, FILE_ORDER)\n",
    "\n",
    "    # 2) Group-based plots\n",
    "    for col, data in summaries.items():\n",
    "        print(f\"\\nCreating plots for grouping by '{col}'...\")\n",
    "        plot_group_overall_bars(\n",
    "            col=col,\n",
    "            by_group_overall=data[\"by_group_overall\"],\n",
    "            score_cols=score_cols,\n",
    "            out_dir=out_dir,\n",
    "        )\n",
    "        plot_group_heatmaps(\n",
    "            col=col,\n",
    "            by_file_and_group=data[\"by_file_and_group\"],\n",
    "            score_cols=score_cols,\n",
    "            out_dir=out_dir,\n",
    "            file_order=FILE_ORDER,\n",
    "        )\n",
    "\n",
    "    # Quick sanity check in stdout\n",
    "    print(\"\\n=== Overall means per file (head) ===\")\n",
    "    print(overall_by_file.head())\n",
    "\n",
    "    for col, data in summaries.items():\n",
    "        print(f\"\\n=== Means by file and {col} (head) ===\")\n",
    "        print(data[\"by_file_and_group\"].head())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
